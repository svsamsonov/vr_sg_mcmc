{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as spstats\n",
    "from scipy import signal\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import scipy.sparse as sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from potentials import potentialRegression\n",
    "from baselines import construct_ESVM_kernel,split_dataset,set_function,standartize\n",
    "from optimize import Run_eval_test,optimize_parallel_new\n",
    "from samplers import MCMC_sampler,Generate_train\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Datasets:</p>\n",
    "<ol>\n",
    "    <li>Eeg $(N=14\\,980,\\ d=15)$</li>\n",
    "    <li>Susy $(N=100\\,000,\\ d=19)$</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"eeg\" # Switch between \"eeg\" and \"susy\" \n",
    "\n",
    "intercept = True # Do we include the intercept\n",
    "\n",
    "method = {\"sampler\":\"ULA\",\"burn_type\":\"SGLDFP\",\"main_type\":\"SGLDFP\"} # Sampling method\n",
    "\n",
    "# Switch between \"posterior_prob_point\", \"posterior_prob_mean\", \"posterior_prob_variance\", \"posterior_mean\"\n",
    "f_type = \"posterior_prob_mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning parameters\n",
    "step = 1*10**(-1)\n",
    "n_traj_train = 5 # Number of independent MCMC trajectories for train\n",
    "n_traj_test = 100 # Number of independent MCMC trajectories for test\n",
    "\n",
    "if (dataset == \"eeg\"):    \n",
    "    batch_size = 1*15 # Batch size for stochastic gradient\n",
    "    N_b = 5*10**3 # Burn-in period\n",
    "    N_train = 1*10**4 # Length of the train trajectory\n",
    "    N_test = 1*10**5 # Length of the test trajectories\n",
    "elif (dataset == \"susy\"): \n",
    "    batch_size =3*19 # Batch size for stochastic gradient\n",
    "    N_b = 1*10**4 # Burn in period\n",
    "    N_train = 1*10**5 # Number of samples on which we optimize\n",
    "    N_test = 1*10**5 # Number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (dataset == \"eeg\"):   \n",
    "    data = pd.read_csv(\"data/eeg.csv\",header=None)\n",
    "    outliers_inds = np.array([13179,11509,898,10386])\n",
    "    Y = data.iloc[:,-1]\n",
    "    X = data.iloc[:,:-1]    \n",
    "elif (dataset == \"susy\"): \n",
    "    data = pd.read_csv(\"data/susy.csv\",header=None)\n",
    "    outliers_inds = np.array([267630])\n",
    "    Y = data.iloc[:,0]\n",
    "    X = data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the outliers\n",
    "if (outliers_inds.size!=0):\n",
    "    X_processed = np.delete(np.asarray(X),outliers_inds,0)\n",
    "    mask = np.ones(len(Y),dtype = bool)\n",
    "    mask[outliers_inds] = False\n",
    "    Y_processed = Y[mask]\n",
    "    Y_processed = np.asarray(Y_processed)\n",
    "    X_processed = np.asarray(X_processed)\n",
    "else:\n",
    "    Y_processed = np.asarray(Y)\n",
    "    X_processed = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (f_type == \"posterior_mean\"):\n",
    "    X_train,X_train = standartize(X_processed,X_processed,intercept=intercept)\n",
    "    Y_train = Y_processed\n",
    "else:\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X_processed,Y_processed,test_size=100,random_state=1812,stratify=Y_processed)\n",
    "    X_train,X_test = standartize(X_train,X_test,intercept=intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#std of initial point\n",
    "optim_params = {\n",
    "    \"compute_fp\":True,\n",
    "    \"GD\":False,\n",
    "    \"stochastic\":False,\n",
    "    \"order\":1,\n",
    "    \"n_restarts\":5,\n",
    "    \"batch_size\":100,\n",
    "    \"sigma\":1.0,\n",
    "    \"gtol\":1e-6,\n",
    "    \"gamma\":5e-4,\n",
    "    \"weight_decay\":0.995,\n",
    "    \"loop_length\":100,\n",
    "    \"n_loops\":300\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct kernel\n",
    "W_train_spec = construct_ESVM_kernel(N_train)\n",
    "W_test_spec = construct_ESVM_kernel(N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating potential\n",
    "Cur_pot = potentialRegression(Y_train, X_train, typ = \"l\",optim_params = optim_params, batch_size = batch_size, print_info = True)\n",
    "d = Cur_pot.d #dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample for variance reduction\n",
    "res = Generate_train(n_traj_train, method, Cur_pot, step, N_b, N_train, d)\n",
    "res = np.asarray(res)\n",
    "traj,traj_grad = res[:,0,:,:],res[:,1,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of function values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select variables to optimize, other values are available ONLY for \"posterior_prob_point\" and \"posterior_mean\"\n",
    "inds_arr = np.array([0])\n",
    "#initialize vector of function values\n",
    "if (f_type == \"posterior_mean\"):\n",
    "    params = None\n",
    "else:\n",
    "    params = {\"X\":X_test,\"Y\":Y_test}\n",
    "f_vals = set_function(f_type,traj,inds_arr,params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training coefficients for EVM and ESVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of restarts during optimization\n",
    "n_restarts = 2\n",
    "#deviation of starting points\n",
    "sigma = 1\n",
    "#tolerance (for the norm of gradient)\n",
    "tol = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here $LS$ estimate corresponds to simple least-squares problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_ESVM_1,A_EVM_1,A_LS_1 = optimize_parallel_new(1,inds_arr,f_vals,traj,traj_grad,W_train_spec,n_restarts,tol,sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate $1$ independent test trajectory of the same length with same burn-in, to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_test,traj_grad_test = ULA(1453,Cur_pot,step, N_b, N_train, d,method[\"burn_type\"],method[\"main_type\"])\n",
    "traj_test = np.asarray([traj])\n",
    "traj_grad_test = np.asarray([traj_grad])\n",
    "f_vals_test = set_function(f_type,traj,inds_arr,params)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do main plots in this section\n",
    "from statsmodels.tsa.stattools import acf\n",
    "#indices of trajectory and variable, ypu can play around them in case element-wise test functions\n",
    "ex_num=0\n",
    "var_num=0\n",
    "#part of trajectory tp lot\n",
    "N1 = 50000\n",
    "N2 = 50500\n",
    "#number of covariances to visualize\n",
    "N_cov_1 = 0\n",
    "N_cov = 100\n",
    "\n",
    "vect_vanilla = f_vals_test[ex_num,:,var_num] \n",
    "vect_EVM = f_vals_test[ex_num,:,var_num] + traj_grad_test[ex_num,:,:] @ A_EVM_1[var_num,:]\n",
    "vect_ESVM = f_vals_test[ex_num,:,var_num] + traj_grad_test[ex_num,:,:] @ A_ESVM_1[var_num,:]\n",
    "\n",
    "sample_acf_vanilla = acf(vect_vanilla, unbiased = True,fft = True,nlags=100)\n",
    "sample_acf_EVM = acf(vect_EVM, unbiased = True,fft = True,nlags=100)\n",
    "sample_acf_ESVM = acf(vect_ESVM, unbiased = True,fft = True,nlags=100)\n",
    "#\"\"\"\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3,figsize=(20,5),gridspec_kw={'width_ratios': [1,1,2]})\n",
    "ax1.set_title('Vanilla trajectory')\n",
    "ax1.plot(N1+np.arange(len(vect_vanilla[N1:N2])),vect_vanilla[N1:N2],color='r')\n",
    "ax2.set_title('Trajectory after ESVM')\n",
    "ax2.plot(N1+np.arange(len(vect_ZAV[N1:N2])),vect_ESVM[N1:N2],color='r')\n",
    "ax3.set_title('Sample autocorrelation')\n",
    "ax3.fill_between(N_cov_1+np.arange(N_cov-N_cov_1),sample_acf_vanilla[N_cov_1:N_cov],facecolor='blue',alpha=0.5,label='acf vanilla')\n",
    "ax3.fill_between(N_cov_1+np.arange(N_cov-N_cov_1),sample_acf_EVM[N_cov_1:N_cov],facecolor='green',alpha=0.5,label='acf EVM')\n",
    "ax3.fill_between(N_cov_1+np.arange(N_cov-N_cov_1),sample_acf_ESVM[N_cov_1:N_cov],facecolor='red',alpha=0.5,label='acf ESVM')\n",
    "ax3.legend(fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce 3 plots in a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = {\"sampler\":\"ULA\",\"burn_type\":\"SGLDFP\",\"main_type\":\"SGLDFP\"} # Sampling method\n",
    "# Switch between \"posterior_prob_point\", \"posterior_prob_mean\", \"posterior_prob_variance\", \"posterior_mean\"\n",
    "f_type = \"posterior_prob_mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_arr = np.array([0])\n",
    "params = {\"X\":X_test,\"Y\":Y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_function_coefs(batch_size): \n",
    "    Cur_pot = potentialRegression(Y_train, X_train, typ = \"l\",optim_params = optim_params, batch_size = batch_size, print_info = True)\n",
    "    d = Cur_pot.d\n",
    "    res = Generate_train(n_traj_train, method, Cur_pot, step, N_b, N_train, d)\n",
    "    res = np.asarray(res)\n",
    "    traj,traj_grad = res[:,0,:,:],res[:,1,:,:]\n",
    "    f_vals = set_function(f_type,traj,inds_arr,params)\n",
    "    #number of restarts during optimization\n",
    "    n_restarts = 2\n",
    "    #deviation of starting points\n",
    "    sigma = 4.0\n",
    "    #tolerance (norm of gradient needed to terminate)\n",
    "    tol = 1e-5\n",
    "    #optimization\n",
    "    A_ESVM_1,A_EVM_1,A_LS_1 = optimize_parallel_new(1,inds_arr,f_vals,traj,traj_grad,W_train_spec,n_restarts,tol,sigma)\n",
    "    traj,traj_grad = ULA(1453,Cur_pot,step, N_b, N_train, d, method[\"burn_type\"],method[\"main_type\"])\n",
    "    traj = np.asarray([traj])\n",
    "    traj_grad = np.asarray([traj_grad])\n",
    "    f_vals_test = set_function(f_type,traj,inds_arr,params)\n",
    "    return f_vals_test,traj_grad,A_ZAV_1,A_ZV_1   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For batch sizes $5$, $15$ and $150$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_vals_5,traj_grad_5,A_ESVM_5,A_EVM_5 = generate_function_coefs(batch_size=5)\n",
    "f_vals_15,traj_grad_15,A_ESVM_15,A_EVM_15 = generate_function_coefs(batch_size=15)\n",
    "f_vals_150,traj_grad_150,A_ESVM_150,A_EVM_150 = generate_function_coefs(batch_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_func_values(f_vals,traj_grad,EVM_coef,ESVM_coef, ex_num=0,var_num=0):\n",
    "    vect_vanilla = f_vals[ex_num,:,var_num] \n",
    "    vect_EVM = f_vals[ex_num,:,var_num] + traj_grad[ex_num,:,:] @ EVM_coef[var_num,:]\n",
    "    vect_ESVM = f_vals[ex_num,:,var_num] + traj_grad[ex_num,:,:] @ ESVM_coef[var_num,:]\n",
    "    return vect_vanilla,vect_EVM,vect_ESVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acfs(f_vals,f_vals_EVM,f_vals_ESVM,nlags = 100,ex_num=0,var_num=0):\n",
    "    sample_acf_vanilla = acf(f_vals, unbiased = True,fft = True,nlags=nlags)\n",
    "    sample_acf_EVM = acf(f_vals_EVM, unbiased = True,fft = True,nlags=nlags)\n",
    "    sample_acf_ESVM = acf(f_vals_ESVM, unbiased = True,fft = True,nlags=nlags)\n",
    "    return sample_acf_vanilla,sample_acf_EVM,sample_acf_ESVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acovf,acf\n",
    "#number of covariances to visualize\n",
    "N_cov_1 = 0\n",
    "N_cov = 100\n",
    "\n",
    "vect_vanilla_5,vect_EVM_5,vect_ESVM_5 = get_func_values(f_vals_5,traj_grad_5,A_EVM_5,A_ESVM_5)\n",
    "vect_vanilla_15,vect_EVM_15,vect_ESVM_15 = get_func_values(f_vals_15,traj_grad_15,A_EVM_15,A_ESVM_15)\n",
    "vect_vanilla_150,vect_EVM_150,vect_ESVM_150 = get_func_values(f_vals_150,traj_grad_150,A_EVM_150,A_ESVM_150)\n",
    "\n",
    "sample_acf_vanilla_5,sample_acf_EVM_5,sample_acf_ZAV_5 = get_acfs(vect_vanilla_5,vect_EVM_5,vect_ESVM_5)\n",
    "sample_acf_vanilla_15,sample_acf_EVM_15,sample_acf_ZAV_15 = get_acfs(vect_vanilla_15,vect_EVM_15,vect_ESVM_15)\n",
    "sample_acf_vanilla_150,sample_acf_ZV_ESVM,sample_acf_ZAV_150 = get_acfs(vect_vanilla_150,vect_EVM_150,vect_ESVM_150)\n",
    "\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3,figsize=(20,5),gridspec_kw={'width_ratios': [1,1,1]})\n",
    "ax1.set_title('Batch size = 5')\n",
    "ax1.fill_between(N_cov_1+np.arange(N_cov-N_cov_1),sample_acf_vanilla_5[N_cov_1:N_cov],facecolor='blue',alpha=0.5,label='acf vanilla')\n",
    "ax1.fill_between(N_cov_1+np.arange(N_cov-N_cov_1),sample_acf_ZV_5[N_cov_1:N_cov],facecolor='green',alpha=0.5,label='acf EVM')\n",
    "ax1.fill_between(N_cov_1+np.arange(N_cov-N_cov_1),sample_acf_ZAV_5[N_cov_1:N_cov],facecolor='red',alpha=0.5,label='acf ESVM')\n",
    "ax1.legend(fontsize=16)\n",
    "ax2.set_title('Batch size = 15')\n",
    "ax2.fill_between(N_cov_1+np.arange(N_cov-N_cov_1),sample_acf_vanilla_15[N_cov_1:N_cov],facecolor='blue',alpha=0.5,label='acf vanilla')\n",
    "ax2.fill_between(N_cov_1+np.arange(N_cov-N_cov_1),sample_acf_ZV_15[N_cov_1:N_cov],facecolor='green',alpha=0.5,label='acf EVM')\n",
    "ax2.fill_between(N_cov_1+np.arange(N_cov-N_cov_1),sample_acf_ZAV_15[N_cov_1:N_cov],facecolor='red',alpha=0.5,label='acf ESVM')\n",
    "ax2.legend(fontsize=16)\n",
    "ax3.set_title('Batch size = 150')\n",
    "ax3.fill_between(N_cov_1+np.arange(N_cov-N_cov_1),sample_acf_vanilla_150[N_cov_1:N_cov],facecolor='blue',alpha=0.5,label='acf vanilla')\n",
    "ax3.fill_between(N_cov_1+np.arange(N_cov-N_cov_1),sample_acf_ZV_150[N_cov_1:N_cov],facecolor='green',alpha=0.5,label='acf EVM')\n",
    "ax3.fill_between(N_cov_1+np.arange(N_cov-N_cov_1),sample_acf_ZAV_150[N_cov_1:N_cov],facecolor='red',alpha=0.5,label='acf ESVM')\n",
    "ax3.legend(fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
