{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as spstats\n",
    "from scipy import signal\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import scipy.sparse as sparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from potentials import potentialRegression\n",
    "from baselines import construct_ESVM_kernel,split_dataset,set_function,standartize\n",
    "from optimize import Run_eval_test,optimize_parallel_new\n",
    "from samplers import MCMC_sampler,Generate_train\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Datasets:</p>\n",
    "<ol>\n",
    "    <li>Eeg $(N=14\\,980,\\ d=15)$</li>\n",
    "    <li>Susy $(N=500\\,000,\\ d=19)$</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"eeg\" # Switch between \"eeg\" and \"susy\" \n",
    "\n",
    "intercept = True # Do we include the intercept\n",
    "\n",
    "CV2 = False # Do we include second-order control variates\n",
    "\n",
    "method = {\"sampler\":\"ULA\",\"burn_type\":\"SGLD\",\"main_type\":\"SAGA\"} # Sampling method\n",
    "#during burn-in period we use simple SGLD to prevent SAGA stacking at local minima\n",
    "\n",
    "# Switch between \"posterior_prob_point\", \"posterior_prob_mean\", \"posterior_prob_variance\", \"posterior_mean\"\n",
    "f_type = \"posterior_prob_mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning parameters\n",
    "step = 1*10**(-1)\n",
    "n_traj_train = 5 # Number of independent MCMC trajectories for train\n",
    "n_traj_test = 100 # Number of independent MCMC trajectories for test\n",
    "\n",
    "if (dataset == \"eeg\"):    \n",
    "    batch_size = 1*15 # Batch size for stochastic gradient\n",
    "    N_b = 5*10**3 # Burn-in period\n",
    "    N_train = 1*10**4 # Length of the train trajectory\n",
    "    N_test = 1*10**5 # Length of the test trajectories\n",
    "elif (dataset == \"susy\"): \n",
    "    batch_size =3*19 # Batch size for stochastic gradient\n",
    "    N_b = 5*10**4 # Burn in period\n",
    "    N_train = 1*10**5 # Number of samples on which we optimize\n",
    "    N_test = 1*10**6 # Number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (dataset == \"eeg\"):   \n",
    "    data = pd.read_csv(\"data/eeg.csv\",header=None)\n",
    "    outliers_inds = np.array([13179,11509,898,10386])\n",
    "    Y = data.iloc[:,-1]\n",
    "    X = data.iloc[:,:-1]    \n",
    "elif (dataset == \"susy\"): \n",
    "    data = pd.read_csv(\"data/susy.csv\",header=None)\n",
    "    outliers_inds = np.array([267630])\n",
    "    Y = data.iloc[:,0]\n",
    "    X = data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the outliers\n",
    "if (outliers_inds.size!=0):\n",
    "    X_processed = np.delete(np.asarray(X),outliers_inds,0)\n",
    "    mask = np.ones(len(Y),dtype = bool)\n",
    "    mask[outliers_inds] = False\n",
    "    Y_processed = Y[mask]\n",
    "    Y_processed = np.asarray(Y_processed)\n",
    "    X_processed = np.asarray(X_processed)\n",
    "else:\n",
    "    Y_processed = np.asarray(Y)\n",
    "    X_processed = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (f_type == \"posterior_mean\"):\n",
    "    X_train,X_train = standartize(X_processed,X_processed,intercept=intercept)\n",
    "    Y_train = Y_processed\n",
    "else:\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X_processed,Y_processed,test_size=100,random_state=1812,stratify=Y_processed)\n",
    "    X_train,X_test = standartize(X_train,X_test,intercept=intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_params = {\n",
    "    \"compute_fp\":False,\n",
    "    \"GD\":False,\n",
    "    \"stochastic\":False,\n",
    "    \"order\":1,\n",
    "    \"n_restarts\":5,\n",
    "    \"batch_size\":100,\n",
    "    \"sigma\":1.0,\n",
    "    \"gtol\":1e-6,\n",
    "    \"gamma\":5e-4,\n",
    "    \"weight_decay\":0.995,\n",
    "    \"loop_length\":100,\n",
    "    \"n_loops\":300\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct kernel\n",
    "W_train_spec = construct_ESVM_kernel(N_train)\n",
    "W_test_spec = construct_ESVM_kernel(N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating potential\n",
    "Cur_pot = potentialRegression(Y_train, X_train, typ = \"l\",optim_params = optim_params, batch_size = batch_size, print_info = True)\n",
    "d = Cur_pot.d #dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling training trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Generate_train(n_traj_train, method, Cur_pot, step, N_b, N_train, d)\n",
    "res = np.asarray(res)\n",
    "traj,traj_grad = res[:,0,:,:],res[:,1,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of function values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the function you are willing to evaluate is \"posterior_prob_point\" or \"posterior mean\" â€” pass through inds_arr parameter indices of variables, over which you are willing to optimize. For example, in case of \"posterior_prob_point\",\n",
    "\n",
    ">inds_arr = np.array([0])\n",
    "\n",
    "means that you are willing to reduce variance for a point from the test dataset with index $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (f_type == \"posterior_mean\"):\n",
    "    inds_arr = np.array([1]) # Taking the second index (not intercept)\n",
    "    params = None\n",
    "else:\n",
    "    params = {\"X\":X_test,\"Y\":Y_test}\n",
    "    inds_arr = np.array([0])\n",
    "    \n",
    "f_vals = set_function(f_type,traj,inds_arr,params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training coefficients for EVM and ESVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_restarts = 2 # Number of restarts during optimization\n",
    "sigma = 1 # Deviation of starting points\n",
    "tol = 1e-5 # Tolerance (for the norm of gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_ESVM_1,A_EVM_1,A_LS_1 = optimize_parallel_new(1,inds_arr,f_vals,traj,traj_grad,W_train_spec,n_restarts,tol,sigma)\n",
    "if CV2:\n",
    "    A_ESVM_2,A_EVM_2,A_LS_2 = optimize_parallel_new(2,inds_arr,f_vals,traj,traj_grad,W_train_spec,n_restarts,tol,sigma)\n",
    "else:\n",
    "    A_ESVM_2,A_EVM_2,A_LS_2 = np.zeros((2,d**2+d)),np.zeros((2,d**2+d)),np.zeros((2,d**2+d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficients for control variates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Coefficients for ESVM\")\n",
    "print(A_ESVM_1)\n",
    "print(\"Coefficients for EVM\")\n",
    "print(A_EVM_1)\n",
    "print(\"Coefficients for LS\")\n",
    "print(A_LS_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if CV2:\n",
    "    print(\"Coefficients for ESVM\")\n",
    "    print(A_ESVM_2)\n",
    "    print(\"Coefficients for EVM\")\n",
    "    print(A_EVM_2)\n",
    "    print(\"Coefficients for LS\")\n",
    "    print(A_LS_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing EVM and ESVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary, put respective matrices into it\n",
    "CV_dict = {\"ESVM\":[A_ESVM_1,A_ESVM_2],\"EVM\":[A_EVM_1,A_EVM_2],\"LS\":[A_LS_1,A_LS_2]}\n",
    "# Number of cores exploited for the computation of the independent trajectories\n",
    "# by deault, all available cores on the machine\n",
    "nbcores = multiprocessing.cpu_count()\n",
    "trav = Pool(nbcores)\n",
    "res = trav.starmap(Run_eval_test, [(i,method,inds_arr,Cur_pot,W_test_spec,CV_dict,step,N_b,N_test,d,params,f_type) for i in range (n_traj_test)])\n",
    "trav.close()\n",
    "res_arr = np.asarray(res) # Saving results as np.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Estimators\")\n",
    "print(\"SGLDFP {}\".format(np.mean(res_arr[:,0,0,:],axis=0)))\n",
    "print(\"ESVM pol=1 {}\".format(np.mean(res_arr[:,0,1,:],axis=0)))\n",
    "#print(\"ESVM pol=2 {}\".format(np.mean(res_arr[:,0,2,:],axis=0)))\n",
    "print(\"EVM pol=1 {}\".format(np.mean(res_arr[:,0,3,:],axis=0)))\n",
    "#print(\"EVM pol=2 {}\".format(np.mean(res_arr[:,0,4,:],axis=0)))\n",
    "print(\"LS pol=1 {}\".format(np.mean(res_arr[:,0,3,:],axis=0)))\n",
    "#print(\"LS pol=2 {}\".format(np.mean(res_arr[:,0,4,:],axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variances\")\n",
    "print(\"Vanilla MC {}\".format(np.mean(res_arr[:,1,0,:],axis=0)))\n",
    "print(\"ZAV pol=1 {}\".format(np.mean(res_arr[:,1,1,:],axis=0)))\n",
    "#print(\"ZAV pol=2 {}\".format(np.mean(res_arr[:,1,2,:],axis=0)))\n",
    "print(\"ZV pol=1 {}\".format(np.mean(res_arr[:,1,3,:],axis=0)))\n",
    "#print(\"ZV pol=2 {}\".format(np.mean(res_arr[:,1,4,:],axis=0)))\n",
    "print(\"LS pol=1 {}\".format(np.mean(res_arr[:,1,5,:],axis=0)))\n",
    "#print(\"LS pol=2 {}\".format(np.mean(res_arr[:,1,6,:],axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ind = 0 # Index to plot\n",
    "title = dataset.upper()+\" dataset\"\n",
    "labels = ['Vanilla\\n SAGA-LD', 'SAGA-LD \\nwith EVM','SAGA-LD \\nwith ESVM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plots\n",
    "if CV2: \n",
    "    data1 = [res_arr[:,0,0,var_ind],res_arr[:,0,3,var_ind],res_arr[:,0,1,var_ind]]\n",
    "    data2 = [res_arr[:,0,0,var_ind],res_arr[:,0,4,var_ind],res_arr[:,0,2,var_ind]]\n",
    "    violplot_2ind(data1, data2, title, labels)\n",
    "else: \n",
    "    data = [res_arr[:,0,0,var_ind],res_arr[:,0,3,var_ind],res_arr[:,0,1,var_ind]] \n",
    "    violplot_ind(data, title, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot\n",
    "if CV2: \n",
    "    data1 = [res_arr[:,0,0,var_ind],res_arr[:,0,3,var_ind],res_arr[:,0,1,var_ind]]\n",
    "    data2 = [res_arr[:,0,0,var_ind],res_arr[:,0,4,var_ind],res_arr[:,0,2,var_ind]]\n",
    "    boxplot_2ind(data1, data2, title, labels)\n",
    "else: \n",
    "    data = [res_arr[:,0,0,var_ind],res_arr[:,0,3,var_ind],res_arr[:,0,1,var_ind]] \n",
    "    boxplot_ind(data, title, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
