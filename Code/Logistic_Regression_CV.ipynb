{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.polynomial as P\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import ZVnbrosse\n",
    "from zv_cv import Eval_ZVCV\n",
    "from potentials import GaussPotential,GaussMixture,GausMixtureIdent,GausMixtureSame,potentialRegression\n",
    "from samplers import MCMC_sampler,Generate_train,ULA_light\n",
    "from baselines import set_function,construct_ESVM_kernel,GenerateSigma,standartize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from martingale import approx_q,test_traj\n",
    "from optimize import Run_eval_test,optimize_parallel_new \n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"pima\" # Switch between \"swiss\" and \"pima\" \n",
    "intercept = True # Do we include the intercept\n",
    "typ = \"logistic\" #logistic or probit are expected\n",
    "test_size = 20\n",
    "\n",
    "# Switch between \"posterior_prob_point\", \"posterior_prob_mean\", \"posterior_prob_variance\", \"posterior_mean\"\n",
    "if typ == \"logistic\":\n",
    "    f_type = \"posterior_prob_mean\"\n",
    "elif typ == \"probit\":\n",
    "    f_type = \"posterior_prob_mean_point\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (dataset == \"swiss\"):\n",
    "    data = pd.read_csv(\"./data/swiss.csv\",header=None)\n",
    "    outliers_inds = np.array([])\n",
    "    Y = data.iloc[:,-1]\n",
    "    X = data.iloc[:,:-1]\n",
    "elif (dataset == \"eeg\"):   \n",
    "    data = pd.read_csv(\"./data/eeg.csv\",header=None)\n",
    "    outliers_inds = np.array([13179,11509,898,10386])\n",
    "    Y = data.iloc[:,-1]\n",
    "    X = data.iloc[:,:-1]\n",
    "elif (dataset == \"pima\"):\n",
    "    data = pd.read_csv(\"./data/pima.csv\",header=None)\n",
    "    outliers_inds = np.array([])\n",
    "    Y = data.iloc[:,-1]\n",
    "    X = data.iloc[:,:-1]\n",
    "elif (dataset == \"susy\"): \n",
    "    data = pd.read_csv(\"data/susy.csv\",header=None)\n",
    "    outliers_inds = np.array([267630])\n",
    "    Y = data.iloc[:,0]\n",
    "    X = data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the outliers\n",
    "if (outliers_inds.size!=0):\n",
    "    X_processed = np.delete(np.asarray(X),outliers_inds,0)\n",
    "    mask = np.ones(len(Y),dtype = bool)\n",
    "    mask[outliers_inds] = False\n",
    "    Y_processed = Y[mask]\n",
    "    Y_processed = np.asarray(Y_processed)\n",
    "    X_processed = np.asarray(X_processed)\n",
    "else:\n",
    "    Y_processed = np.asarray(Y)\n",
    "    X_processed = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (f_type == \"posterior_mean\" or f_type == \"sum\"):\n",
    "    X_train,X_train = standartize(X_processed,X_processed,intercept=intercept)\n",
    "    Y_train = Y_processed\n",
    "else:\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X_processed,Y_processed,test_size=test_size,random_state=1812,stratify=Y_processed)\n",
    "    X_train,X_test = standartize(X_train,X_test,intercept=intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (f_type == \"posterior_mean\" or f_type == \"sum\"):\n",
    "    inds_arr = np.array([1]) # Taking the second index (not intercept)\n",
    "    params = None\n",
    "else:\n",
    "    params = {\"X\":X_test,\"Y\":Y_test}\n",
    "    inds_arr = np.array([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating potential\n",
    "Cur_pot = potentialRegression(Y_train, X_train, typ, print_info = True)\n",
    "d = Cur_pot.d\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_burn = 1*10**4 # Burn in period\n",
    "N_train = 1*10**5 # Number of samples on which we optimize\n",
    "step = 1.0 # Step size\n",
    "n_traj = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate methods (EVM and CV methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = {\"sampler\":\"RWM\",\"burn_type\":\"full\",\"main_type\":\"full\"} # Sampling method\n",
    "\n",
    "if sampler[\"sampler\"] == \"ULA\":\n",
    "    res = Generate_train(n_traj, sampler, Cur_pot, step, N_burn, N_train, d)\n",
    "    res = np.asarray(res)\n",
    "    traj,traj_grad = res[:,0,:,:],res[:,1,:,:]\n",
    "else:\n",
    "    res = Generate_train(n_traj, sampler, Cur_pot, step, N_burn, N_train, d)\n",
    "    traj = []\n",
    "    traj_grad = []\n",
    "    for i in range(len(res)):\n",
    "        traj.append(res[i][0])\n",
    "        traj_grad.append(res[i][1])\n",
    "        print(\"accepted = \",res[i][2])\n",
    "    traj = np.asarray(traj)\n",
    "    traj_grad = np.asarray(traj_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traj.shape)\n",
    "print(traj_grad.shape)\n",
    "traj_grad = (-1)*traj_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = 20\n",
    "W_test = construct_ESVM_kernel(N_train,bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seed = 1453\n",
    "nbcores = multiprocessing.cpu_count()\n",
    "trav = Pool(nbcores)\n",
    "res = trav.starmap(Eval_ZVCV, [(traj[i,:,:],traj_grad[i,:,:],f_type,params,W_test) for i in range (n_traj)])\n",
    "trav.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_arr = np.asarray(res)\n",
    "print(res_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"ode/mala_step_1e-5_obs_20_sum_15_04.npy\",res_arr)\n",
    "print(\"Average vr rates:\")\n",
    "print(\"ZV-1:\",np.mean(res_arr[:,1,0]/res_arr[:,1,1]))\n",
    "print(\"CV-1:\",np.mean(res_arr[:,1,0]/res_arr[:,1,3]))\n",
    "print(\"ZV-2:\",np.mean(res_arr[:,1,0]/res_arr[:,1,2]))\n",
    "print(\"CV-2:\",np.mean(res_arr[:,1,0]/res_arr[:,1,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"\"\n",
    "labels = ['Vanilla\\n ULA', 'ULA \\nwith ZV-1', 'ULA \\nwith CV-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [res_arr[:,0,0],res_arr[:,0,1],res_arr[:,0,3]] \n",
    "boxplot_ind(data, title, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"\"\n",
    "labels = ['ULA \\nwith ZV-1', 'ULA \\nwith CV-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [res_arr[:,0,1],res_arr[:,0,3]] \n",
    "boxplot_ind(data, title, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"\"\n",
    "labels = ['Vanilla\\n ULA', 'ULA \\nwith ZV-2', 'ULA \\nwith CV-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [res_arr[:,0,0],res_arr[:,0,2],res_arr[:,0,4]] \n",
    "boxplot_ind(data, title, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"\"\n",
    "labels = ['ULA \\nwith ZV-2', 'ULA \\nwith CV-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [res_arr[:,0,2],res_arr[:,0,4]] \n",
    "boxplot_ind(data, title, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
